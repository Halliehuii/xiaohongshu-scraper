import re
import json
import requests
from bs4 import BeautifulSoup
from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import List, Optional
import uvicorn

# åˆ›å»ºFastAPIå®ä¾‹
app = FastAPI(title="å°çº¢ä¹¦å…ƒæ•°æ®æŠ“å–API", description="ä»å°çº¢ä¹¦é“¾æ¥ä¸­æå–æ ‡é¢˜ã€æè¿°å’Œå›¾ç‰‡URLçš„API")

# å®šä¹‰è¯·æ±‚æ¨¡å‹
class XHSLinkRequest(BaseModel):
    input_text: str

# å®šä¹‰å“åº”æ¨¡å‹
class XHSMetadataResponse(BaseModel):
    title: str
    description: str
    image_urls: List[str]
    original_url: str
    extracted_url: str

# å®šä¹‰HTMLæ ·ä¾‹è¯·æ±‚æ¨¡å‹
class HTMLSampleRequest(BaseModel):
    html_sample: str

def extract_xiaohongshu_url(input_text):
    """
    ä»æ‰‹æœºç«¯å¤åˆ¶çš„æ–‡æœ¬ä¸­æå–å°çº¢ä¹¦URL
    
    Args:
        input_text (str): ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ï¼Œä¾‹å¦‚ï¼š
        "34 æ‹“éº»æ…§å­å‘å¸ƒäº†ä¸€ç¯‡å°çº¢ä¹¦ç¬”è®°ï¼Œå¿«æ¥çœ‹å§ï¼ğŸ˜† tnk9IKuwcqYQnJK ğŸ˜† http://xhslink.com/a/IGTNc5Db7WEab"
        
    Returns:
        str: æå–å‡ºçš„URLï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
    """
    # åŒ¹é… http://xhslink.com/a/ å¼€å¤´çš„å®Œæ•´URL
    pattern = r'http://xhslink\.com/[a-zA-Z0-9/]+'
    match = re.search(pattern, input_text)
    
    if match:
        url = match.group(0)
        return url
        
    return None

def follow_redirect(short_url):
    """
    è·Ÿè¸ªçŸ­é“¾æ¥çš„é‡å®šå‘ï¼Œè·å–æœ€ç»ˆURL
    
    Args:
        short_url (str): çŸ­é“¾æ¥URL
        
    Returns:
        str: é‡å®šå‘åçš„æœ€ç»ˆURL
    """
    try:
        response = requests.head(short_url, allow_redirects=True)
        return response.url
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·Ÿè¸ªé“¾æ¥é‡å®šå‘å¤±è´¥: {str(e)}")

def extract_metadata(url, debug=False):
    """
    ä»å°çº¢ä¹¦é¡µé¢ä¸­æå–å…ƒæ•°æ®
    
    Args:
        url (str): å°çº¢ä¹¦å¸–å­URL
        debug (bool): æ˜¯å¦è¿”å›HTMLæºç 
        
    Returns:
        dict: åŒ…å«æ ‡é¢˜ã€æè¿°å’Œå›¾ç‰‡URLçš„å­—å…¸
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
    }
    
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        
        # ä¿å­˜HTMLå†…å®¹ä»¥ä¾¿è°ƒè¯•
        html_content = response.text
        print(f"è·å–åˆ°HTMLå†…å®¹ï¼Œé•¿åº¦: {len(html_content)} å­—èŠ‚")
        
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # æå–æ ‡é¢˜ - ä½¿ç”¨å±æ€§é€‰æ‹©å™¨
        title = ""
        # å°è¯•å¤šç§å¯èƒ½çš„é€‰æ‹©å™¨æ–¹å¼
        title_meta = soup.find('meta', attrs={'property': 'og:title'})
        if title_meta and title_meta.get('content'):
            title = title_meta.get('content')
            print(f"ä»BeautifulSoupæå–åˆ°æ ‡é¢˜: {title}")
        
        # æå–æè¿°
        description = ""
        desc_meta = soup.find('meta', attrs={'name': 'description'})
        if desc_meta and desc_meta.get('content'):
            description = desc_meta.get('content')
            print(f"ä»BeautifulSoupæå–åˆ°æè¿°: {description}")
        
        # æå–å›¾ç‰‡URL - ä½¿ç”¨å±æ€§é€‰æ‹©å™¨
        image_urls = []
        image_metas = soup.find_all('meta', attrs={'property': 'og:image'})
        for img_meta in image_metas:
            if img_meta.get('content'):
                image_url = img_meta.get('content')
                if image_url not in image_urls:  # é¿å…é‡å¤
                    image_urls.append(image_url)
        
        if image_urls:
            print(f"ä»BeautifulSoupæå–åˆ°å›¾ç‰‡URLæ•°é‡: {len(image_urls)}")
        
        # å¦‚æœé€šè¿‡BeautifulSoupæ— æ³•æå–åˆ°å…ƒæ•°æ®ï¼Œå°è¯•ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç›´æ¥ä»HTMLå†…å®¹æå–
        if not title or not description or not image_urls:
            print("ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä»HTMLä¸­æå–å…ƒæ•°æ®...")
            
            # æå–æ ‡é¢˜
            title_match = re.search(r'<meta\s+(?:[^>]*?\s+)?property="og:title"(?:\s+[^>]*?)?content="([^"]*)"', html_content, re.IGNORECASE)
            if title_match and not title:
                title = title_match.group(1)
                print(f"é€šè¿‡æ­£åˆ™è¡¨è¾¾å¼æå–åˆ°æ ‡é¢˜: {title}")
            
            # æå–æè¿°
            desc_match = re.search(r'<meta\s+(?:[^>]*?\s+)?name="description"(?:\s+[^>]*?)?content="([^"]*)"', html_content, re.IGNORECASE)
            if desc_match and not description:
                description = desc_match.group(1)
                print(f"é€šè¿‡æ­£åˆ™è¡¨è¾¾å¼æå–åˆ°æè¿°: {description}")
            
            # æå–æ‰€æœ‰og:imageæ ‡ç­¾
            image_matches = re.findall(r'<meta\s+(?:[^>]*?\s+)?property="og:image"(?:\s+[^>]*?)?content="([^"]*)"', html_content, re.IGNORECASE)
            if image_matches:
                for img_url in image_matches:
                    if img_url not in image_urls:
                        image_urls.append(img_url)
                print(f"é€šè¿‡æ­£åˆ™è¡¨è¾¾å¼æå–åˆ°å›¾ç‰‡URLæ•°é‡: {len(image_urls)}")
        
        # å¦‚æœä»ç„¶æ— æ³•æå–åˆ°è¶³å¤Ÿçš„å…ƒæ•°æ®ï¼Œå°è¯•ç›´æ¥å¤„ç†ç¤ºä¾‹ä¸­çš„HTMLä»£ç 
        if not title and "<meta name=\"og:title\"" in html_content or "<meta property=\"og:title\"" in html_content:
            print("å°è¯•ç›´æ¥ä»HTMLä»£ç ç‰‡æ®µæå–...")
            # è¿™ç§æƒ…å†µå¯èƒ½æ˜¯ç”¨æˆ·ç›´æ¥æä¾›äº†HTMLä»£ç ç‰‡æ®µè€Œä¸æ˜¯URL
            
            # æå–æ ‡é¢˜ - ç›´æ¥å­—ç¬¦ä¸²å¤„ç†
            title_pattern = r'<meta (?:name|property)="og:title" content="([^"]*)">'
            title_match = re.search(title_pattern, html_content)
            if title_match:
                title = title_match.group(1)
                print(f"ç›´æ¥ä»HTMLä»£ç æå–åˆ°æ ‡é¢˜: {title}")
            
            # æå–æè¿° - ç›´æ¥å­—ç¬¦ä¸²å¤„ç†
            desc_pattern = r'<meta name="description" content="([^"]*)">'
            desc_match = re.search(desc_pattern, html_content)
            if desc_match:
                description = desc_match.group(1)
                print(f"ç›´æ¥ä»HTMLä»£ç æå–åˆ°æè¿°: {description}")
            
            # æå–å›¾ç‰‡ - ç›´æ¥å­—ç¬¦ä¸²å¤„ç†
            image_pattern = r'<meta (?:name|property)="og:image" content="([^"]*)">'
            image_matches = re.findall(image_pattern, html_content)
            if image_matches:
                for img_url in image_matches:
                    if img_url not in image_urls:
                        image_urls.append(img_url)
                print(f"ç›´æ¥ä»HTMLä»£ç æå–åˆ°å›¾ç‰‡URLæ•°é‡: {len(image_urls)}")
        
        result = {
            'title': title,
            'description': description,
            'image_urls': image_urls
        }
        
        # å¦‚æœæ˜¯è°ƒè¯•æ¨¡å¼ï¼Œè¿”å›HTMLæºç 
        if debug:
            result['html_source'] = html_content
            
        return result
        
    except Exception as e:
        print(f"æå–å…ƒæ•°æ®å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æå–å…ƒæ•°æ®å¤±è´¥: {str(e)}")

@app.post("/extract/", response_model=XHSMetadataResponse)
async def extract_xiaohongshu_metadata(request: XHSLinkRequest):
    """
    ä»å°çº¢ä¹¦é“¾æ¥ä¸­æå–å…ƒæ•°æ®
    
    ä»ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ä¸­æå–å°çº¢ä¹¦é“¾æ¥ï¼Œç„¶åè·å–è¯¥é“¾æ¥çš„æ ‡é¢˜ã€æè¿°å’Œå›¾ç‰‡URL
    
    - **input_text**: ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ï¼ŒåŒ…å«å°çº¢ä¹¦åˆ†äº«é“¾æ¥
    
    è¿”å›:
    - **title**: å¸–å­æ ‡é¢˜
    - **description**: å¸–å­æè¿°
    - **image_urls**: å›¾ç‰‡URLåˆ—è¡¨
    - **original_url**: åŸå§‹çŸ­é“¾æ¥
    - **extracted_url**: æœ€ç»ˆçš„é“¾æ¥
    """
    # ä»è¾“å…¥æ–‡æœ¬ä¸­æå–URL
    short_url = extract_xiaohongshu_url(request.input_text)
    if not short_url:
        raise HTTPException(status_code=400, detail="æœªèƒ½ä»è¾“å…¥æ–‡æœ¬ä¸­æå–åˆ°æœ‰æ•ˆçš„å°çº¢ä¹¦é“¾æ¥")
    
    # è·Ÿè¸ªé‡å®šå‘è·å–æœ€ç»ˆURL
    final_url = follow_redirect(short_url)
    
    # æå–å…ƒæ•°æ®
    metadata = extract_metadata(final_url)
    
    return XHSMetadataResponse(
        title=metadata['title'],
        description=metadata['description'],
        image_urls=metadata['image_urls'],
        original_url=short_url,
        extracted_url=final_url
    )

@app.post("/extract_from_html/", response_model=XHSMetadataResponse)
async def extract_from_html_sample(request: HTMLSampleRequest):
    """
    ç›´æ¥ä»HTMLæ ·ä¾‹ä¸­æå–å…ƒæ•°æ®
    
    ä»ç”¨æˆ·æä¾›çš„HTMLä»£ç æ ·ä¾‹ä¸­æå–æ ‡é¢˜ã€æè¿°å’Œå›¾ç‰‡URL
    
    - **html_sample**: HTMLä»£ç æ ·ä¾‹ï¼ŒåŒ…å«metaæ ‡ç­¾
    
    è¿”å›:
    - **title**: å¸–å­æ ‡é¢˜
    - **description**: å¸–å­æè¿°
    - **image_urls**: å›¾ç‰‡URLåˆ—è¡¨
    - **original_url**: æ ·ä¾‹URL (ç©ºå­—ç¬¦ä¸²)
    - **extracted_url**: æ ·ä¾‹URL (ç©ºå­—ç¬¦ä¸²)
    """
    html_content = request.html_sample
    
    print("ä»HTMLæ ·ä¾‹ä¸­æå–å…ƒæ•°æ®...")
    
    # æå–æ ‡é¢˜
    title = ""
    title_pattern = r'<meta\s+[^>]*?(?:name|property)="og:title"[^>]*?content="([^"]+)"'
    title_match = re.search(title_pattern, html_content)
    if title_match:
        title = title_match.group(1)
        print(f"æå–åˆ°æ ‡é¢˜: {title}")
    
    # æå–æè¿°
    description = ""
    desc_pattern = r'<meta\s+[^>]*?name="description"[^>]*?content="([^"]+)"'
    desc_match = re.search(desc_pattern, html_content)
    if desc_match:
        description = desc_match.group(1)
        print(f"æå–åˆ°æè¿°: {description}")
    
    # æå–å›¾ç‰‡URL
    image_urls = []
    image_pattern = r'<meta\s+[^>]*?(?:name|property)="og:image"[^>]*?content="([^"]+)"'
    image_matches = re.findall(image_pattern, html_content)
    if image_matches:
        for img_url in image_matches:
            if img_url not in image_urls:
                image_urls.append(img_url)
        print(f"æå–åˆ°å›¾ç‰‡URLæ•°é‡: {len(image_urls)}")
    
    # å¦‚æœæœªèƒ½æå–åˆ°ä¿¡æ¯ï¼Œè¿”å›é”™è¯¯
    if not title and not description and not image_urls:
        raise HTTPException(status_code=400, detail="æœªèƒ½ä»HTMLæ ·ä¾‹ä¸­æå–åˆ°ä»»ä½•å…ƒæ•°æ®")
    
    return XHSMetadataResponse(
        title=title,
        description=description,
        image_urls=image_urls,
        original_url="",
        extracted_url=""
    )

@app.get("/")
async def read_root():
    return {"message": "å°çº¢ä¹¦å…ƒæ•°æ®æŠ“å–API", "version": "1.0"}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8080) 